{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c556b3-e391-416a-8174-d865f62aecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc0108-c70e-4f4d-853f-fb23d60349ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not any([\"StreamHandler\" in str(handler) for handler in logger.handlers]):\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad17f9-d0a3-4c3f-9ee8-eb4be39ea79a",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca965b-6109-440f-9744-52ec49c3a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from numpy.testing import assert_array_equal\n",
    "from scipy import signal\n",
    "from src.dataloader import make_evaluation_dataloader_without_random_cropping\n",
    "from src.loss_maker import (\n",
    "    AbsDiffDivergence,\n",
    "    AbsDiffTemperature,\n",
    "    ChannelwiseMse,\n",
    "    DiffOmegaVectorNorm,\n",
    "    DiffVelocityVectorNorm,\n",
    "    MaskedL1Loss,\n",
    "    MaskedL1LossNearWall,\n",
    "    MaskedL2Loss,\n",
    "    MaskedL2LossNearWall,\n",
    "    MyL1Loss,\n",
    "    MyL2Loss,\n",
    "    ResidualContinuity,\n",
    "    Ssim3dLoss,\n",
    "    calc_mask_near_build_wall,\n",
    ")\n",
    "from src.model_maker import make_model\n",
    "from src.optim_helper import evaluate\n",
    "from src.utils import calc_early_stopping_patience, set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d372b-2447-4ac1-a2bf-64de60ed16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef937c7-5417-4e1c-adcf-997d80d133de",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb641a52-2756-4bc7-821a-2e80c8dea3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "DL_DATA_DIR = pathlib.Path(f\"{ROOT_DIR}/data/DL_data\")\n",
    "DL_INFERENCE_DIR = pathlib.Path(f\"{ROOT_DIR}/data/DL_inferences\")\n",
    "\n",
    "# FIG_DIR = f\"{ROOT_DIR}/doc/wccm2022_presentation_fig\"\n",
    "# os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffc45c-6978-4688-b2ff-18192ffaf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    logger.info(\"GPU is used.\")\n",
    "else:\n",
    "    logger.error(\"No GPU. CPU is used.\")\n",
    "    # raise Exception(\"No GPU. CPU is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90201a3-398d-49f3-bacf-b6dd4dabbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATHS = sorted(\n",
    "    glob.glob(f\"{ROOT_DIR}/pytorch/config/new_lr_unet_gconv_change_datashape_ddp/*.yml\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87859e3b-b5fe-4915-abb6-37b6df7985ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_IS_IN_BUILD = np.load(f\"{ROOT_DIR}/data/DL_data/10/hr_is_in_build.npy\")\n",
    "LR_IS_IN_BUILD = np.load(f\"{ROOT_DIR}/data/DL_data/10/lr_is_in_build.npy\")\n",
    "\n",
    "HR_BUILDING_HEIGHT_PATH = f\"{ROOT_DIR}/datascience/script/EleTopoZ_HR.txt\"\n",
    "LR_BUILDING_HEIGHT_PATH = f\"{ROOT_DIR}/datascience/script/EleTopoZ_LR.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51976f6-d98b-4612-9a22-1c529d08878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    if \"tutorial\" in config_path:\n",
    "        continue\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "\n",
    "    _dir = f\"{ROOT_DIR}/data/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8774df9a-b430-4882-bf05-880fa505b493",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff548b5-f2f7-46a8-b9de-e5056d79d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionalize(data, means, scales):\n",
    "    assert data.ndim == means.ndim == scales.ndim\n",
    "    assert data.shape[1] == 4\n",
    "    return data * scales + means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b8e40-b8a8-4247-a59b-aa1762e78d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab6e7b-319f-4ae9-b13c-273e678dd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name, config_info in tqdm(CONFIGS.items(), total=len(CONFIGS)):\n",
    "    if \"z0_2475_825\" not in config_name and \"z2_2475_825\" not in config_name:\n",
    "        continue\n",
    "\n",
    "    inference_dir = DL_INFERENCE_DIR / config_info[\"experiment_name\"] / config_name\n",
    "    if os.path.exists(inference_dir):\n",
    "        logger.info(f\"Skip {config_name} because inference dir already exists.\")\n",
    "        continue\n",
    "\n",
    "    os.makedirs(inference_dir, exist_ok=False)\n",
    "    logger.info(f\"\\n{config_name} is being evaluated.\")\n",
    "\n",
    "    config = config_info[\"config\"]\n",
    "\n",
    "    test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "        config, DL_DATA_DIR, batch_size=1\n",
    "    )\n",
    "\n",
    "    model = make_model(config).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(config_info[\"weight_path\"], map_location=DEVICE))\n",
    "    _ = model.eval()\n",
    "\n",
    "    means = torch.Tensor(config[\"data\"][\"means\"])[None, :, None, None, None]\n",
    "    scales = torch.Tensor(config[\"data\"][\"stds\"])[None, :, None, None, None]\n",
    "    test_file_paths = test_loader.dataset.lr_files\n",
    "\n",
    "    assert len(test_file_paths) == len(test_loader)\n",
    "\n",
    "    for path, (Xs, bs, ys) in tqdm(\n",
    "        zip(test_file_paths, test_loader), total=len(test_loader)\n",
    "    ):\n",
    "        out_file_name = os.path.basename(path).replace(\"LR\", \"SR\")\n",
    "        out_file_path = str(inference_dir / out_file_name)\n",
    "\n",
    "        if os.path.exists(out_file_path):\n",
    "            continue\n",
    "\n",
    "        bs = bs.unsqueeze(1)  # add channel dim\n",
    "        assert Xs.shape[1:] == (4, 8, 80, 80)\n",
    "        assert bs.shape[1:] == (1, 32, 320, 320)\n",
    "        assert ys.shape[1:] == (4, 32, 320, 320)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(Xs.to(DEVICE), bs.to(DEVICE)).cpu()\n",
    "            preds = dimensionalize(preds, means, scales)\n",
    "\n",
    "        np.save(out_file_path, preds.numpy())\n",
    "\n",
    "    del model, test_loader, test_file_paths\n",
    "    _ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2920ce-dd70-421b-9570-926100518505",
   "metadata": {},
   "source": [
    "# Measure inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501c9cf-d384-47e9-80d5-cc7e7957f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(WARNING)\n",
    "config_name = \"z0_2475_825\"\n",
    "config_info = CONFIGS[config_name]\n",
    "\n",
    "config = config_info[\"config\"]\n",
    "\n",
    "test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "    config, DL_DATA_DIR, batch_size=1\n",
    ")\n",
    "\n",
    "model = make_model(config).to(DEVICE)\n",
    "model.load_state_dict(torch.load(config_info[\"weight_path\"], map_location=DEVICE))\n",
    "_ = model.eval()\n",
    "\n",
    "means = torch.Tensor(config[\"data\"][\"means\"])[None, :, None, None, None]\n",
    "scales = torch.Tensor(config[\"data\"][\"stds\"])[None, :, None, None, None]\n",
    "test_file_paths = test_loader.dataset.lr_files\n",
    "\n",
    "for Xs, bs, ys in tqdm(test_loader, total=len(test_loader)):\n",
    "    bs = bs.unsqueeze(1)  # add channel dim\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(Xs.to(DEVICE), bs.to(DEVICE)).cpu()\n",
    "        preds = dimensionalize(preds, means, scales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af661707-0b5f-4d16-b30b-784f4fd6968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 900/900 [04:09<00:00, 3.76it/s]\n",
    "(4 * 60 + 9) / 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1dc721-afa0-4a82-baae-95373464d20d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
