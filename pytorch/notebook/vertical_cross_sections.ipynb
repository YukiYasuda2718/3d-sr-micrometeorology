{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45157bf-ff22-480d-aabd-6e9ab7b13c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d72992-2bb1-4d03-a614-632e8d7ddcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b326ee1a-9c2e-4b15-9aea-609a1faf6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xarray==2022.10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beb6ed7-9ae0-4da0-b84a-ccdfae72c03f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da989884-2fdc-48a6-acb1-aaa16c93fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# import xarray as xr\n",
    "import yaml\n",
    "from numpy.testing import assert_array_equal\n",
    "from scipy import interpolate, signal\n",
    "from src.dataloader import (\n",
    "    get_all_new_lr_data_dir_paths,\n",
    "    make_dataloaders,\n",
    "    make_evaluation_dataloader_without_random_cropping,\n",
    "    split_into_train_valid_test_dirs,\n",
    ")\n",
    "from src.loss_maker import (\n",
    "    AbsDiffDivergence,\n",
    "    AbsDiffTemperature,\n",
    "    ChannelwiseMse,\n",
    "    DiffOmegaVectorNorm,\n",
    "    DiffVelocityVectorNorm,\n",
    "    MaskedL1Loss,\n",
    "    MaskedL1LossNearWall,\n",
    "    MaskedL2Loss,\n",
    "    MaskedL2LossNearWall,\n",
    "    MyL1Loss,\n",
    "    MyL2Loss,\n",
    "    ResidualContinuity,\n",
    "    Ssim3dLoss,\n",
    "    calc_mask_near_build_wall,\n",
    ")\n",
    "from src.model_maker import make_model\n",
    "from src.optim_helper import evaluate\n",
    "from src.ssim import SSIM3D\n",
    "from src.utils import calc_early_stopping_patience, read_pickle, set_seeds, write_pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551d72d-90d6-46ed-9efb-221dc6f8ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668f49f-9704-4abc-8822-9735134b0540",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ef5a8-1268-4a39-99d2-14ab23ea5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "DL_DATA_DIR = pathlib.Path(f\"{ROOT_DIR}/data/DL_data\")\n",
    "DL_INFERENCE_DIR = pathlib.Path(f\"{ROOT_DIR}/data/DL_inferences\")\n",
    "MAKE_EPS_FILES = False\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "FIG_DIR = f\"{ROOT_DIR}/doc/paper_fig\"\n",
    "os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f7e0b-ae01-4a72-97b7-620cc930902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"new_lr_unet_gconv_change_datashape_ddp\"\n",
    "CONFIG_PATHS = sorted(glob.glob(f\"{ROOT_DIR}/pytorch/config/{EXPERIMENT_NAME}/*.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad78c4d8-d051-44d7-b7de-e5a264e6f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_IS_IN_BUILD = torch.from_numpy(\n",
    "    np.load(f\"{ROOT_DIR}/data/DL_data/10/hr_is_in_build.npy\")\n",
    ")\n",
    "LR_IS_IN_BUILD = torch.from_numpy(\n",
    "    np.load(f\"{ROOT_DIR}/data/DL_data/10/lr_is_in_build.npy\")\n",
    ")\n",
    "\n",
    "HR_BUILDING_HEIGHT_PATH = f\"{ROOT_DIR}/datascience/script/EleTopoZ_HR.txt\"\n",
    "LR_BUILDING_HEIGHT_PATH = f\"{ROOT_DIR}/datascience/script/EleTopoZ_LR.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a277e606-af86-4e3a-bc60-107592ead4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    if \"tutorial\" in config_path:\n",
    "        continue\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "\n",
    "    _dir = f\"{ROOT_DIR}/data/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2f74c-3d9e-4f94-b16e-763311ebfccb",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86d301-fe01-4f80-bad3-904ff6c74817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimensionalize(data, means, scales):\n",
    "    assert data.ndim == means.ndim == scales.ndim\n",
    "    assert data.shape[1] == 4\n",
    "    return data * scales + means\n",
    "\n",
    "\n",
    "def undimensionalize(data, means, scales):\n",
    "    assert data.ndim == means.ndim == scales.ndim\n",
    "    assert data.shape[1] == 4\n",
    "    return (data - means) / scales\n",
    "\n",
    "\n",
    "def fill_na(xs: torch.Tensor):\n",
    "\n",
    "    _xs = F.interpolate(xs[:, None], scale_factor=4, mode=\"trilinear\").squeeze()\n",
    "    _is_in_build = F.interpolate(\n",
    "        LR_IS_IN_BUILD[:, None], scale_factor=4, mode=\"nearest\"\n",
    "    ).squeeze()\n",
    "    assert _xs.shape == _is_in_build.shape == HR_IS_IN_BUILD.shape\n",
    "\n",
    "    _xs = torch.where(_is_in_build == 0, _xs, torch.full_like(_xs, torch.nan))\n",
    "\n",
    "    _xs = xr.DataArray(_xs)\n",
    "    assert (np.isnan(_xs.values)).sum() > 0, \"No Nan values\"\n",
    "\n",
    "    _xs = (\n",
    "        _xs.interpolate_na(dim=\"dim_1\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "        .interpolate_na(dim=\"dim_2\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "        .interpolate_na(dim=\"dim_3\", method=\"linear\", fill_value=\"extrapolate\")\n",
    "    )\n",
    "\n",
    "    assert (np.isnan(_xs.values)).sum() == 0\n",
    "\n",
    "    return _xs\n",
    "\n",
    "\n",
    "def read_building_height(\n",
    "    building_path: str, target_col: str, margin: int = 0\n",
    ") -> np.ndarray:\n",
    "\n",
    "    with open(building_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    cols = [\"i\", \"j\", \"Ez\", \"Tz\", \"Tzl\"]\n",
    "    _dict = {}\n",
    "    for i, line in enumerate(lines[1:]):  # skip header\n",
    "        splits = list(\n",
    "            map(lambda s: s.strip(), filter(lambda s: s != \"\", line.split(\" \")))\n",
    "        )\n",
    "        _dict[i] = {k: v for k, v in zip(cols, splits)}\n",
    "\n",
    "    df_topography = pd.DataFrame.from_dict(_dict).T\n",
    "\n",
    "    for col in cols:\n",
    "        if col == \"i\" or col == \"j\":\n",
    "            df_topography[col] = df_topography[col].astype(int)\n",
    "        else:\n",
    "            df_topography[col] = df_topography[col].astype(float)\n",
    "\n",
    "    ret = pd.pivot_table(\n",
    "        data=df_topography[[\"i\", \"j\", target_col]],\n",
    "        values=target_col,\n",
    "        index=\"i\",\n",
    "        columns=\"j\",\n",
    "        aggfunc=\"max\",\n",
    "    ).values\n",
    "\n",
    "    if margin == 0:\n",
    "        return ret\n",
    "    else:\n",
    "        return ret[margin:-margin, margin:-margin]\n",
    "\n",
    "\n",
    "def calc_is_in_building(\n",
    "    tz: np.ndarray, ez: np.ndarray, actual_levs: np.ndarray\n",
    ") -> np.ndarray:\n",
    "\n",
    "    # tz = build height, ez = ground height, both from sea surface\n",
    "\n",
    "    assert tz.shape == ez.shape\n",
    "    assert len(tz.shape) == 2  # y and x\n",
    "    assert len(actual_levs.shape) == 1  # z\n",
    "\n",
    "    _shape = actual_levs.shape + tz.shape  # dims = (z, y, x)\n",
    "\n",
    "    is_in_building = np.zeros(_shape)\n",
    "    for j in range(is_in_building.shape[1]):  # y dim\n",
    "        for i in range(is_in_building.shape[2]):  # x dim\n",
    "            t, e = tz[j, i], ez[j, i]\n",
    "            if t <= e:  # BH is lower than or equal to the ground.\n",
    "                continue  # This means there is no building.\n",
    "\n",
    "            idx_top_of_build = (actual_levs < t).argmin()\n",
    "            is_in_building[:idx_top_of_build, j, i] = 1\n",
    "\n",
    "    return is_in_building\n",
    "\n",
    "\n",
    "def calc_mean_and_errors(values):\n",
    "    assert values.shape == (5, 32)\n",
    "    means = torch.mean(values, dim=0)  # average over batch dim\n",
    "    errs = torch.stack(\n",
    "        [means - torch.min(values, dim=0)[0], torch.max(values, dim=0)[0] - means]\n",
    "    )\n",
    "    logger.info(f\"mean shape = {means.shape}\")\n",
    "    logger.info(f\"error shape = {errs.shape}\")\n",
    "    return means, errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcde764-0114-466e-a5c5-e45f6ceae19e",
   "metadata": {},
   "source": [
    "# Horizontal sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10eb7a58-464c-4420-bc23-efbf7755e99f",
   "metadata": {},
   "source": [
    "## case: Z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b893d67-3c47-4240-aed0-c0623175887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = EXPERIMENT_NAME\n",
    "config_name = \"z0_2475_825\"\n",
    "index_sample = 300\n",
    "\n",
    "#################\n",
    "\n",
    "inference_dir = DL_INFERENCE_DIR / experiment_name / config_name\n",
    "inference_paths = sorted(glob.glob(str(inference_dir / \"*.npy\")))\n",
    "\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "config = CONFIGS[config_name][\"config\"]\n",
    "logger.setLevel(WARNING)\n",
    "test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "    config, DL_DATA_DIR, batch_size=1\n",
    ")\n",
    "test_dataset = test_loader.dataset\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "means = torch.Tensor(config[\"data\"][\"means\"])[None, :, None, None, None]\n",
    "scales = torch.Tensor(config[\"data\"][\"stds\"])[None, :, None, None, None]\n",
    "\n",
    "assert os.path.basename(inference_paths[index_sample]) == os.path.basename(\n",
    "    test_dataset.lr_files[index_sample]\n",
    ").replace(\"LR\", \"SR\")\n",
    "\n",
    "\n",
    "Xs, bs, ys = test_dataset.__getitem__(index_sample)\n",
    "\n",
    "Xs_scaled = dimensionalize(Xs[None, ...], means, scales).squeeze()\n",
    "bs = bs[None, ...]\n",
    "ys_scaled = dimensionalize(ys[None, ...], means, scales).squeeze()\n",
    "\n",
    "preds_scaled = torch.from_numpy(np.load(inference_paths[index_sample])).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67eaaf-cbe5-43e6-8e6c-ba45e189eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cmap = {\n",
    "    \"tm\": \"turbo\",\n",
    "    \"vl\": \"YlOrRd\",\n",
    "    \"vp\": \"YlGnBu\",\n",
    "    \"vr\": \"viridis\",\n",
    "}\n",
    "\n",
    "sx, ex = 170, 230\n",
    "sy, ey = 70, 130\n",
    "assert ey - sy == ex - sx\n",
    "\n",
    "use_data_vim_vmax = True\n",
    "dict_vmin = {\"tm\": 32.00, \"vl\": -4.0, \"vp\": -3.0, \"vr\": -1.0}\n",
    "dict_vmax = {\"tm\": 34.00, \"vl\": 2.0, \"vp\": 3.0, \"vr\": 1.0}\n",
    "\n",
    "tex_labels = {\n",
    "    \"tm\": r\"$T$\",\n",
    "    \"vl\": r\"$u$\",\n",
    "    \"vp\": r\"$v$\",\n",
    "    \"vr\": r\"$w$\",\n",
    "}\n",
    "\n",
    "lr_scale_factor = 4\n",
    "hr_scale_factor = 1\n",
    "enhance_edges = False\n",
    "\n",
    "var_names = {0: \"tm\", 1: \"vl\", 2: \"vp\", 3: \"vr\"}\n",
    "var_units = {0: \"[$^\\circ$C]\", 1: \"[m/s]\", 2: \"[m/s]\", 3: \"[m/s]\"}\n",
    "\n",
    "var_dataset = OrderedDict(\n",
    "    {\n",
    "        \"HR\": ys_scaled,\n",
    "        \"LR\": Xs_scaled,\n",
    "        \"SR\": preds_scaled,\n",
    "        # \"HR-SR\": ys_scaled - preds_scaled,\n",
    "    }\n",
    ")\n",
    "\n",
    "ttl_labels = {\n",
    "    \"HR\": \"Ground Truth\",\n",
    "    \"LR\": \"LR Input\",\n",
    "    \"SR\": \"SR Inference\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx_height in [0, 8]:\n",
    "\n",
    "    enhance_edges = False if idx_height == 0 else True\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=[8, 10])\n",
    "    Gx, Gy = None, None\n",
    "\n",
    "    for i, j, idx_var in zip([0, 1, 2, 3], [-1, -1, -1, -1], [0, 1, 2, 3]):\n",
    "        var_name = var_names[idx_var]\n",
    "        var_unit = var_units[idx_var]\n",
    "        ground_truth, bldg = None, None\n",
    "\n",
    "        for var_kind in var_dataset.keys():\n",
    "            j += 1\n",
    "\n",
    "            ax = axes[i, j]\n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            if \"HR\" in var_kind or \"SR\" in var_kind:\n",
    "                scale_factor = hr_scale_factor\n",
    "                assert scale_factor == 1\n",
    "                is_in_bldg = HR_IS_IN_BUILD[:, :32, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - HR_IS_IN_BUILD[:, :32, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "            else:\n",
    "                scale_factor = lr_scale_factor\n",
    "                assert scale_factor == 4\n",
    "                is_in_bldg = LR_IS_IN_BUILD[:, :8, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - LR_IS_IN_BUILD[:, :8, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "\n",
    "            bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "            is_in_bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    is_in_bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "            assert bldg.shape == is_in_bldg.shape == (4, 32, 320, 320)\n",
    "\n",
    "            bldg = bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "            is_in_bldg = is_in_bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            if enhance_edges:\n",
    "                edge = signal.convolve2d(is_in_bldg, np.ones((3, 3)), \"same\")\n",
    "                edge = np.where(edge > 0, np.ones_like(edge), np.zeros_like(edge))\n",
    "                edge = np.where(edge * bldg > 0, np.ones_like(bldg), np.nan)\n",
    "\n",
    "            data = torch.nn.functional.interpolate(\n",
    "                var_dataset[var_kind][None, ...],\n",
    "                scale_factor=scale_factor,\n",
    "                mode=\"nearest\",\n",
    "            ).squeeze()\n",
    "\n",
    "            assert data.shape == (4, 32, 320, 320)\n",
    "            if var_kind == \"LR\":\n",
    "                assert var_dataset[var_kind].shape == (4, 8, 80, 80)\n",
    "            else:\n",
    "                assert var_dataset[var_kind].shape == (4, 32, 320, 320)\n",
    "\n",
    "            data = data[idx_var, idx_height].numpy().transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            data = np.where(bldg, data, np.nan)\n",
    "\n",
    "            if Gx is None or Gy is None:\n",
    "                Gx = 5 * np.arange(data.shape[0])\n",
    "                Gy = 5 * np.arange(data.shape[1])\n",
    "                Gx, Gy = np.meshgrid(Gx, Gy, indexing=\"ij\")\n",
    "\n",
    "            if var_kind != \"HR-SR\" and var_name == \"tm\":\n",
    "                data -= 273.15\n",
    "\n",
    "            if var_kind == \"HR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                # print(var_name, vmin, vmax)\n",
    "\n",
    "            if var_kind == \"HR-SR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                abs_max = max([np.abs(vmin), np.abs(vmax)])\n",
    "                vmax = abs_max\n",
    "                vmin = -abs_max\n",
    "                my_cmap = cm.get_cmap(\"seismic\").copy()\n",
    "                my_cmap.set_bad(\"white\")\n",
    "                ttl = f\"{var_kind} {var_unit}\"\n",
    "            else:\n",
    "                my_cmap = cm.get_cmap(dict_cmap[var_name]).copy()\n",
    "                my_cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "                ttl_label = ttl_labels[var_kind]\n",
    "                ttl = f\"{ttl_label}\\n{tex_labels[var_name]} {var_unit}\"\n",
    "\n",
    "            if not use_data_vim_vmax:\n",
    "                vmin = dict_vmin[var_name]\n",
    "                vmax = dict_vmax[var_name]\n",
    "\n",
    "            contours = ax.pcolormesh(Gx, Gy, data, cmap=my_cmap, vmin=vmin, vmax=vmax)\n",
    "            fig.colorbar(\n",
    "                contours,\n",
    "                ax=ax,\n",
    "                format=\"%.1f\",\n",
    "                ticks=np.linspace(vmin, vmax, 4, endpoint=True),\n",
    "                extend=\"both\",\n",
    "            )\n",
    "            ax.set_title(ttl)\n",
    "\n",
    "            if enhance_edges:\n",
    "                ax.pcolormesh(\n",
    "                    Gx, Gy, edge, cmap=\"binary\", vmin=0.9, vmax=1.01, alpha=0.2\n",
    "                )\n",
    "\n",
    "    # The height index zero of the original HR array is located at 17.5 m\n",
    "    # The bottom of this cell is located at 15.0 m\n",
    "    height_meter = 5 * (idx_height) + 17.5\n",
    "\n",
    "    header = \"(a)\" if idx_height == 0 else \"(b)\"\n",
    "\n",
    "    plt.suptitle(f\"{header} Height = {height_meter - 14.5} [m]\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # fig.savefig(\n",
    "    #     f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.jpg\",\n",
    "    #     dpi=300,\n",
    "    # )\n",
    "    # if MAKE_EPS_FILES:\n",
    "    #     fig.savefig(\n",
    "    #         f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.eps\",\n",
    "    #         dpi=300,\n",
    "    #     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca75b08a-e891-467a-ba74-c8ef6259f170",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cmap = {\n",
    "    \"tm\": \"turbo\",\n",
    "    \"vl\": \"Spectral\",\n",
    "    \"vp\": \"inferno\",\n",
    "    \"vr\": \"coolwarm\",\n",
    "}\n",
    "\n",
    "sx, ex = 170, 230\n",
    "sy, ey = 70, 130\n",
    "assert ey - sy == ex - sx\n",
    "\n",
    "use_data_vim_vmax = True\n",
    "dict_vmin = {\"tm\": 32.00, \"vl\": -4.0, \"vp\": -3.0, \"vr\": -1.0}\n",
    "dict_vmax = {\"tm\": 34.00, \"vl\": 2.0, \"vp\": 3.0, \"vr\": 1.0}\n",
    "\n",
    "tex_labels = {\n",
    "    \"tm\": r\"$T$\",\n",
    "    \"vl\": r\"$u$\",\n",
    "    \"vp\": r\"$v$\",\n",
    "    \"vr\": r\"$w$\",\n",
    "}\n",
    "\n",
    "lr_scale_factor = 4\n",
    "hr_scale_factor = 1\n",
    "enhance_edges = False\n",
    "\n",
    "var_names = {0: \"tm\", 1: \"vl\", 2: \"vp\", 3: \"vr\"}\n",
    "var_units = {0: \"[$^\\circ$C]\", 1: \"[m/s]\", 2: \"[m/s]\", 3: \"[m/s]\"}\n",
    "\n",
    "var_dataset = OrderedDict(\n",
    "    {\n",
    "        \"HR\": ys_scaled,\n",
    "        \"LR\": Xs_scaled,\n",
    "        \"SR\": preds_scaled,\n",
    "        # \"HR-SR\": ys_scaled - preds_scaled,\n",
    "    }\n",
    ")\n",
    "\n",
    "ttl_labels = {\n",
    "    \"HR\": \"Ground Truth\",\n",
    "    \"LR\": \"LR Input\",\n",
    "    \"SR\": \"SR Inference\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx_height in [0, 8]:\n",
    "\n",
    "    enhance_edges = True  # False if idx_height == 0 else True\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=[8, 10])\n",
    "    Gx, Gy = None, None\n",
    "\n",
    "    for i, j, idx_var in zip([0, 1, 2, 3], [-1, -1, -1, -1], [0, 1, 2, 3]):\n",
    "        var_name = var_names[idx_var]\n",
    "        var_unit = var_units[idx_var]\n",
    "        ground_truth, bldg = None, None\n",
    "\n",
    "        for var_kind in var_dataset.keys():\n",
    "            j += 1\n",
    "\n",
    "            ax = axes[i, j]\n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            if \"HR\" in var_kind or \"SR\" in var_kind:\n",
    "                scale_factor = hr_scale_factor\n",
    "                assert scale_factor == 1\n",
    "                is_in_bldg = HR_IS_IN_BUILD[:, :32, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - HR_IS_IN_BUILD[:, :32, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "            else:\n",
    "                scale_factor = lr_scale_factor\n",
    "                assert scale_factor == 4\n",
    "                is_in_bldg = LR_IS_IN_BUILD[:, :8, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - LR_IS_IN_BUILD[:, :8, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "\n",
    "            bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "            is_in_bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    is_in_bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "            assert bldg.shape == is_in_bldg.shape == (4, 32, 320, 320)\n",
    "\n",
    "            bldg = bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "            is_in_bldg = is_in_bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            if enhance_edges:\n",
    "                edge = signal.convolve2d(is_in_bldg, np.ones((3, 3)), \"same\")\n",
    "                edge = np.where(edge > 0, np.ones_like(edge), np.zeros_like(edge))\n",
    "                edge = np.where(edge * bldg > 0, np.ones_like(bldg), np.nan)\n",
    "\n",
    "            data = torch.nn.functional.interpolate(\n",
    "                var_dataset[var_kind][None, ...],\n",
    "                scale_factor=scale_factor,\n",
    "                mode=\"nearest\",\n",
    "            ).squeeze()\n",
    "\n",
    "            assert data.shape == (4, 32, 320, 320)\n",
    "            if var_kind == \"LR\":\n",
    "                assert var_dataset[var_kind].shape == (4, 8, 80, 80)\n",
    "            else:\n",
    "                assert var_dataset[var_kind].shape == (4, 32, 320, 320)\n",
    "\n",
    "            data = data[idx_var, idx_height].numpy().transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            data = np.where(bldg, data, np.nan)\n",
    "\n",
    "            if Gx is None or Gy is None:\n",
    "                Gx = 5 * np.arange(data.shape[0])\n",
    "                Gy = 5 * np.arange(data.shape[1])\n",
    "                Gx, Gy = np.meshgrid(Gx, Gy, indexing=\"ij\")\n",
    "\n",
    "            if var_kind != \"HR-SR\" and var_name == \"tm\":\n",
    "                data -= 273.15\n",
    "\n",
    "            if var_kind == \"HR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                # print(var_name, vmin, vmax)\n",
    "\n",
    "            if var_kind == \"HR-SR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                abs_max = max([np.abs(vmin), np.abs(vmax)])\n",
    "                vmax = abs_max\n",
    "                vmin = -abs_max\n",
    "                my_cmap = cm.get_cmap(\"seismic\").copy()\n",
    "                my_cmap.set_bad(\"white\")\n",
    "                ttl = f\"{var_kind} {var_unit}\"\n",
    "            else:\n",
    "                my_cmap = cm.get_cmap(dict_cmap[var_name]).copy()\n",
    "                my_cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "                ttl_label = ttl_labels[var_kind]\n",
    "                ttl = f\"{ttl_label}\\n{tex_labels[var_name]} {var_unit}\"\n",
    "\n",
    "            if not use_data_vim_vmax:\n",
    "                vmin = dict_vmin[var_name]\n",
    "                vmax = dict_vmax[var_name]\n",
    "\n",
    "            contours = ax.pcolormesh(Gx, Gy, data, cmap=my_cmap, vmin=vmin, vmax=vmax)\n",
    "            fig.colorbar(\n",
    "                contours,\n",
    "                ax=ax,\n",
    "                format=\"%.1f\",\n",
    "                ticks=np.linspace(vmin, vmax, 4, endpoint=True),\n",
    "                extend=\"both\",\n",
    "            )\n",
    "            ax.set_title(ttl)\n",
    "\n",
    "            if enhance_edges:\n",
    "                ax.pcolormesh(\n",
    "                    Gx, Gy, edge, cmap=\"binary\", vmin=0.5, vmax=1.0, alpha=0.4\n",
    "                )\n",
    "\n",
    "    # The height index zero of the original HR array is located at 17.5 m\n",
    "    # The bottom of this cell is located at 15.0 m\n",
    "    height_meter = 5 * (idx_height) + 17.5\n",
    "\n",
    "    header = \"(a)\" if idx_height == 0 else \"(b)\"\n",
    "\n",
    "    plt.suptitle(f\"{header} Height = {height_meter - 14.5} [m]\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # fig.savefig(\n",
    "    #     f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}_news_paper.jpg\",\n",
    "    #     dpi=300,\n",
    "    # )\n",
    "    # if MAKE_EPS_FILES:\n",
    "    #     fig.savefig(\n",
    "    #         f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}_news_paper.eps\",\n",
    "    #         dpi=300,\n",
    "    #     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6d507-ccb5-40ec-a147-fc313c5fe9e8",
   "metadata": {},
   "source": [
    "## case: Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980bb51b-b673-4320-af9f-f93152aef0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = EXPERIMENT_NAME\n",
    "config_name = \"z2_2475_825\"\n",
    "index_sample = 300\n",
    "\n",
    "#################\n",
    "\n",
    "inference_dir = DL_INFERENCE_DIR / experiment_name / config_name\n",
    "inference_paths = sorted(glob.glob(str(inference_dir / \"*.npy\")))\n",
    "\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "config = CONFIGS[config_name][\"config\"]\n",
    "logger.setLevel(WARNING)\n",
    "test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "    config, DL_DATA_DIR, batch_size=1\n",
    ")\n",
    "test_dataset = test_loader.dataset\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "means = torch.Tensor(config[\"data\"][\"means\"])[None, :, None, None, None]\n",
    "scales = torch.Tensor(config[\"data\"][\"stds\"])[None, :, None, None, None]\n",
    "\n",
    "assert os.path.basename(inference_paths[index_sample]) == os.path.basename(\n",
    "    test_dataset.lr_files[index_sample]\n",
    ").replace(\"LR\", \"SR\")\n",
    "\n",
    "\n",
    "Xs, bs, ys = test_dataset.__getitem__(index_sample)\n",
    "\n",
    "Xs_scaled = dimensionalize(Xs[None, ...], means, scales).squeeze()\n",
    "bs = bs[None, ...]\n",
    "ys_scaled = dimensionalize(ys[None, ...], means, scales).squeeze()\n",
    "\n",
    "preds_scaled = torch.from_numpy(np.load(inference_paths[index_sample])).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4221eae6-2dfd-463c-bbe1-82920147e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cmap = {\n",
    "    \"tm\": \"turbo\",\n",
    "    \"vl\": \"YlOrRd\",\n",
    "    \"vp\": \"YlGnBu\",\n",
    "    \"vr\": \"viridis\",\n",
    "}\n",
    "\n",
    "sx, ex = 170, 230\n",
    "sy, ey = 70, 130\n",
    "assert ey - sy == ex - sx\n",
    "\n",
    "use_data_vim_vmax = True\n",
    "dict_vmin = {\"tm\": 32.00, \"vl\": -4.0, \"vp\": -3.0, \"vr\": -1.0}\n",
    "dict_vmax = {\"tm\": 34.00, \"vl\": 2.0, \"vp\": 3.0, \"vr\": 1.0}\n",
    "\n",
    "tex_labels = {\n",
    "    \"tm\": r\"$T$\",\n",
    "    \"vl\": r\"$u$\",\n",
    "    \"vp\": r\"$v$\",\n",
    "    \"vr\": r\"$w$\",\n",
    "}\n",
    "\n",
    "lr_scale_factor = 4\n",
    "hr_scale_factor = 1\n",
    "enhance_edges = False\n",
    "\n",
    "var_names = {0: \"tm\", 1: \"vl\", 2: \"vp\", 3: \"vr\"}\n",
    "var_units = {0: \"[$^\\circ$C]\", 1: \"[m/s]\", 2: \"[m/s]\", 3: \"[m/s]\"}\n",
    "\n",
    "var_dataset = OrderedDict(\n",
    "    {\n",
    "        \"HR\": ys_scaled,\n",
    "        \"LR\": Xs_scaled,\n",
    "        \"SR\": preds_scaled,\n",
    "        # \"HR-SR\": ys_scaled - preds_scaled,\n",
    "    }\n",
    ")\n",
    "\n",
    "ttl_labels = {\n",
    "    \"HR\": \"Ground Truth\",\n",
    "    \"LR\": \"LR Input\",\n",
    "    \"SR\": \"SR Inference\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx_height in [0, 8]:\n",
    "\n",
    "    enhance_edges = False if idx_height == 0 else True\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=[8, 10])\n",
    "    Gx, Gy = None, None\n",
    "\n",
    "    for i, j, idx_var in zip([0, 1, 2, 3], [-1, -1, -1, -1], [0, 1, 2, 3]):\n",
    "        var_name = var_names[idx_var]\n",
    "        var_unit = var_units[idx_var]\n",
    "        ground_truth, bldg = None, None\n",
    "\n",
    "        for var_kind in var_dataset.keys():\n",
    "            j += 1\n",
    "\n",
    "            ax = axes[i, j]\n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            if \"HR\" in var_kind or \"SR\" in var_kind:\n",
    "                scale_factor = hr_scale_factor\n",
    "                assert scale_factor == 1\n",
    "                is_in_bldg = HR_IS_IN_BUILD[:, :32, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - HR_IS_IN_BUILD[:, :32, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "            else:\n",
    "                scale_factor = lr_scale_factor\n",
    "                assert scale_factor == 4\n",
    "                is_in_bldg = LR_IS_IN_BUILD[:, :8, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - LR_IS_IN_BUILD[:, :8, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "\n",
    "            bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "            is_in_bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    is_in_bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "            assert bldg.shape == is_in_bldg.shape == (4, 32, 320, 320)\n",
    "\n",
    "            bldg = bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "            is_in_bldg = is_in_bldg[0, idx_height].transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            if enhance_edges:\n",
    "                edge = signal.convolve2d(is_in_bldg, np.ones((3, 3)), \"same\")\n",
    "                edge = np.where(edge > 0, np.ones_like(edge), np.zeros_like(edge))\n",
    "                edge = np.where(edge * bldg > 0, np.ones_like(bldg), np.nan)\n",
    "\n",
    "            data = torch.nn.functional.interpolate(\n",
    "                var_dataset[var_kind][None, ...],\n",
    "                scale_factor=scale_factor,\n",
    "                mode=\"nearest\",\n",
    "            ).squeeze()\n",
    "\n",
    "            assert data.shape == (4, 32, 320, 320)\n",
    "            if var_kind == \"LR\":\n",
    "                assert var_dataset[var_kind].shape == (4, 8, 80, 80)\n",
    "            else:\n",
    "                assert var_dataset[var_kind].shape == (4, 32, 320, 320)\n",
    "\n",
    "            data = data[idx_var, idx_height].numpy().transpose()[sx:ex, sy:ey]\n",
    "\n",
    "            data = np.where(bldg, data, np.nan)\n",
    "\n",
    "            if Gx is None or Gy is None:\n",
    "                Gx = 5 * np.arange(data.shape[0])\n",
    "                Gy = 5 * np.arange(data.shape[1])\n",
    "                Gx, Gy = np.meshgrid(Gx, Gy, indexing=\"ij\")\n",
    "\n",
    "            if var_kind != \"HR-SR\" and var_name == \"tm\":\n",
    "                data -= 273.15\n",
    "\n",
    "            if var_kind == \"HR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                # print(var_name, vmin, vmax)\n",
    "\n",
    "            if var_kind == \"HR-SR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                abs_max = max([np.abs(vmin), np.abs(vmax)])\n",
    "                vmax = abs_max\n",
    "                vmin = -abs_max\n",
    "                my_cmap = cm.get_cmap(\"seismic\").copy()\n",
    "                my_cmap.set_bad(\"white\")\n",
    "                ttl = f\"{var_kind} {var_unit}\"\n",
    "            else:\n",
    "                my_cmap = cm.get_cmap(dict_cmap[var_name]).copy()\n",
    "                my_cmap.set_bad(\"whitesmoke\")\n",
    "\n",
    "                ttl_label = ttl_labels[var_kind]\n",
    "                ttl = f\"{ttl_label}\\n{tex_labels[var_name]} {var_unit}\"\n",
    "\n",
    "            if not use_data_vim_vmax:\n",
    "                vmin = dict_vmin[var_name]\n",
    "                vmax = dict_vmax[var_name]\n",
    "\n",
    "            contours = ax.pcolormesh(Gx, Gy, data, cmap=my_cmap, vmin=vmin, vmax=vmax)\n",
    "            fig.colorbar(\n",
    "                contours,\n",
    "                ax=ax,\n",
    "                format=\"%.1f\",\n",
    "                ticks=np.linspace(vmin, vmax, 4, endpoint=True),\n",
    "                extend=\"both\",\n",
    "            )\n",
    "            ax.set_title(ttl)\n",
    "\n",
    "            if enhance_edges:\n",
    "                ax.pcolormesh(\n",
    "                    Gx, Gy, edge, cmap=\"binary\", vmin=0.9, vmax=1.01, alpha=0.2\n",
    "                )\n",
    "\n",
    "    # The height index zero of the original HR array is located at 17.5 m\n",
    "    # The bottom of this cell is located at 15.0 m\n",
    "    height_meter = 5 * (idx_height) + 17.5\n",
    "\n",
    "    header = \"(a)\" if idx_height == 0 else \"(b)\"\n",
    "\n",
    "    plt.suptitle(f\"{header} Height = {height_meter - 14.5} [m]\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # fig.savefig(\n",
    "    #     f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.jpg\",\n",
    "    #     dpi=300,\n",
    "    # )\n",
    "    # if MAKE_EPS_FILES:\n",
    "    #     fig.savefig(\n",
    "    #         f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.eps\",\n",
    "    #         dpi=300,\n",
    "    #     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935de30-258b-43ef-aefe-cf00edc03ac3",
   "metadata": {},
   "source": [
    "# Vertical sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2a188c-7757-4bd7-911a-b622a25350dc",
   "metadata": {},
   "source": [
    "## Case: Z0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbd1f8-9674-4c18-93ae-60e35a294dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = EXPERIMENT_NAME\n",
    "config_name = \"z0_2475_825\"\n",
    "index_sample = 300\n",
    "\n",
    "#################\n",
    "\n",
    "inference_dir = DL_INFERENCE_DIR / experiment_name / config_name\n",
    "inference_paths = sorted(glob.glob(str(inference_dir / \"*.npy\")))\n",
    "\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "config = CONFIGS[config_name][\"config\"]\n",
    "logger.setLevel(WARNING)\n",
    "test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "    config, DL_DATA_DIR, batch_size=1\n",
    ")\n",
    "test_dataset = test_loader.dataset\n",
    "logger.setLevel(INFO)\n",
    "\n",
    "means = torch.Tensor(config[\"data\"][\"means\"])[None, :, None, None, None]\n",
    "scales = torch.Tensor(config[\"data\"][\"stds\"])[None, :, None, None, None]\n",
    "\n",
    "assert os.path.basename(inference_paths[index_sample]) == os.path.basename(\n",
    "    test_dataset.lr_files[index_sample]\n",
    ").replace(\"LR\", \"SR\")\n",
    "\n",
    "\n",
    "Xs, bs, ys = test_dataset.__getitem__(index_sample)\n",
    "\n",
    "Xs_scaled = dimensionalize(Xs[None, ...], means, scales).squeeze()\n",
    "bs = bs[None, ...]\n",
    "ys_scaled = dimensionalize(ys[None, ...], means, scales).squeeze()\n",
    "\n",
    "preds_scaled = torch.from_numpy(np.load(inference_paths[index_sample])).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac2d78-578e-4c3d-bf73-6af77a22381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cmap = {\n",
    "    \"tm\": \"turbo\",\n",
    "    \"vl\": \"YlOrRd\",\n",
    "    \"vp\": \"YlGnBu\",\n",
    "    \"vr\": \"viridis\",\n",
    "}\n",
    "\n",
    "sx, ex = 136, 180\n",
    "sz, ez = 0, 12\n",
    "\n",
    "use_data_vim_vmax = True\n",
    "dict_vmin = {\"tm\": 32.00, \"vl\": -4.0, \"vp\": -3.0, \"vr\": -1.0}\n",
    "dict_vmax = {\"tm\": 34.00, \"vl\": 2.0, \"vp\": 3.0, \"vr\": 1.0}\n",
    "\n",
    "tex_labels = {\n",
    "    \"tm\": r\"$T$\",\n",
    "    \"vl\": r\"$u$\",\n",
    "    \"vp\": r\"$v$\",\n",
    "    \"vr\": r\"$w$\",\n",
    "}\n",
    "\n",
    "lr_scale_factor = 4\n",
    "hr_scale_factor = 1\n",
    "\n",
    "var_names = {0: \"tm\", 1: \"vl\", 2: \"vp\", 3: \"vr\"}\n",
    "var_units = {0: \"[$^\\circ$C]\", 1: \"[m/s]\", 2: \"[m/s]\", 3: \"[m/s]\"}\n",
    "\n",
    "var_dataset = OrderedDict(\n",
    "    {\n",
    "        \"HR\": ys_scaled,\n",
    "        \"LR\": Xs_scaled,\n",
    "        \"SR\": preds_scaled,\n",
    "        # \"HR-SR\": ys_scaled - preds_scaled,\n",
    "    }\n",
    ")\n",
    "\n",
    "ttl_labels = {\n",
    "    \"HR\": \"Ground Truth\",\n",
    "    \"LR\": \"LR Input\",\n",
    "    \"SR\": \"SR Inference\",\n",
    "}\n",
    "\n",
    "\n",
    "for idx_lat in [160]:\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 18\n",
    "    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=3, figsize=[20, 9])\n",
    "    Gx, Gz = None, None\n",
    "\n",
    "    for i, j, idx_var in zip([0, 1, 2, 3], [-1, -1, -1, -1], [0, 1, 2, 3]):\n",
    "        var_name = var_names[idx_var]\n",
    "        var_unit = var_units[idx_var]\n",
    "        ground_truth, bldg = None, None\n",
    "\n",
    "        for var_kind in var_dataset.keys():\n",
    "            j += 1\n",
    "\n",
    "            ax = axes[i, j]\n",
    "            ax.set_aspect(\"equal\")\n",
    "            ax.xaxis.set_ticklabels([])\n",
    "            ax.yaxis.set_ticklabels([])\n",
    "            ax.axes.xaxis.set_visible(False)\n",
    "            ax.axes.yaxis.set_visible(False)\n",
    "\n",
    "            if \"HR\" in var_kind or \"SR\" in var_kind:\n",
    "                scale_factor = hr_scale_factor\n",
    "                assert scale_factor == 1\n",
    "                is_in_bldg = HR_IS_IN_BUILD[:, :32, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - HR_IS_IN_BUILD[:, :32, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "            else:\n",
    "                scale_factor = lr_scale_factor\n",
    "                assert scale_factor == 4\n",
    "                is_in_bldg = LR_IS_IN_BUILD[:, :8, :, :].clone().unsqueeze(1)\n",
    "                bldg = torch.tensor(\n",
    "                    1 - LR_IS_IN_BUILD[:, :8, :, :], dtype=torch.float32\n",
    "                ).unsqueeze(1)\n",
    "\n",
    "            bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "            is_in_bldg = (\n",
    "                torch.nn.functional.interpolate(\n",
    "                    is_in_bldg, scale_factor=scale_factor, mode=\"nearest\"\n",
    "                )\n",
    "                .squeeze()\n",
    "                .numpy()\n",
    "            )\n",
    "\n",
    "            assert bldg.shape == is_in_bldg.shape == (4, 32, 320, 320)\n",
    "\n",
    "            bldg = bldg[0, :, idx_lat].transpose()[sx:ex, sz:ez]\n",
    "            is_in_bldg = is_in_bldg[0, :, idx_lat].transpose()[sx:ex, sz:ez]\n",
    "\n",
    "            data = torch.nn.functional.interpolate(\n",
    "                var_dataset[var_kind][None, ...],\n",
    "                scale_factor=scale_factor,\n",
    "                mode=\"nearest\",\n",
    "            ).squeeze()\n",
    "\n",
    "            assert data.shape == (4, 32, 320, 320)\n",
    "            if var_kind == \"LR\":\n",
    "                assert var_dataset[var_kind].shape == (4, 8, 80, 80)\n",
    "            else:\n",
    "                assert var_dataset[var_kind].shape == (4, 32, 320, 320)\n",
    "\n",
    "            data = data[idx_var, :, idx_lat].numpy().transpose()[sx:ex, sz:ez]\n",
    "\n",
    "            data = np.where(bldg, data, np.nan)\n",
    "\n",
    "            if Gx is None or Gz is None:\n",
    "                Gx = 5 * np.arange(data.shape[0])\n",
    "                Gz = 5 * np.arange(data.shape[1])\n",
    "                Gx, Gz = np.meshgrid(Gx, Gz, indexing=\"ij\")\n",
    "\n",
    "            if var_kind != \"HR-SR\" and var_name == \"tm\":\n",
    "                data -= 273.15\n",
    "\n",
    "            if var_kind == \"HR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                # print(var_name, vmin, vmax)\n",
    "\n",
    "            if var_kind == \"HR-SR\":\n",
    "                vmin = np.nanquantile(data.flatten(), 0.05)\n",
    "                vmax = np.nanquantile(data.flatten(), 0.95)\n",
    "                abs_max = max([np.abs(vmin), np.abs(vmax)])\n",
    "                vmax = abs_max\n",
    "                vmin = -abs_max\n",
    "                my_cmap = cm.get_cmap(\"seismic\").copy()\n",
    "                my_cmap.set_bad(\"white\")\n",
    "                ttl = f\"{var_kind} {var_unit}\"\n",
    "            else:\n",
    "                my_cmap = cm.get_cmap(dict_cmap[var_name]).copy()\n",
    "                my_cmap.set_bad(\"lightgray\")\n",
    "\n",
    "                ttl_label = ttl_labels[var_kind]\n",
    "                ttl = f\"{ttl_label}\\n{tex_labels[var_name]} {var_unit}\"\n",
    "\n",
    "            if not use_data_vim_vmax:\n",
    "                vmin = dict_vmin[var_name]\n",
    "                vmax = dict_vmax[var_name]\n",
    "\n",
    "            contours = ax.pcolormesh(Gx, Gz, data, cmap=my_cmap, vmin=vmin, vmax=vmax)\n",
    "            fig.colorbar(\n",
    "                contours,\n",
    "                ax=ax,\n",
    "                format=\"%.1f\",\n",
    "                ticks=np.linspace(vmin, vmax, 4, endpoint=True),\n",
    "                extend=\"both\",\n",
    "            )\n",
    "            ax.set_title(ttl)\n",
    "\n",
    "    # plt.suptitle(f\"idx_lat = {idx_lat}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # fig.savefig(\n",
    "    #     f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.jpg\",\n",
    "    #     dpi=300,\n",
    "    # )\n",
    "    # if MAKE_EPS_FILES:\n",
    "    #     fig.savefig(\n",
    "    #         f\"{FIG_DIR}/SR_fields_{int(height_meter):03}m_{config_name}.eps\",\n",
    "    #         dpi=300,\n",
    "    #     )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf67977-195e-4e09-91bd-113349149813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
