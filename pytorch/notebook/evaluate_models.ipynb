{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c556b3-e391-416a-8174-d865f62aecc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc0108-c70e-4f4d-853f-fb23d60349ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not any([\"StreamHandler\" in str(handler) for handler in logger.handlers]):\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad17f9-d0a3-4c3f-9ee8-eb4be39ea79a",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca965b-6109-440f-9744-52ec49c3a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import gc\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from numpy.testing import assert_array_equal\n",
    "from scipy import signal\n",
    "from src.dataloader import make_evaluation_dataloader_without_random_cropping\n",
    "from src.loss_maker import (\n",
    "    AbsDiffDivergence,\n",
    "    AbsDiffTemperature,\n",
    "    ChannelwiseMse,\n",
    "    DiffOmegaVectorNorm,\n",
    "    DiffVelocityVectorNorm,\n",
    "    MaskedL1Loss,\n",
    "    MaskedL1LossNearWall,\n",
    "    MaskedL2Loss,\n",
    "    MaskedL2LossNearWall,\n",
    "    MixedDivergenceGradientL2LossDivMse,\n",
    "    MixedDivergenceGradientL2LossGrdMse,\n",
    "    MixedDivergenceGradientL2LossMse,\n",
    "    MyL1Loss,\n",
    "    MyL2Loss,\n",
    "    ResidualContinuity,\n",
    "    Ssim3dLoss,\n",
    ")\n",
    "from src.model_maker import make_model\n",
    "from src.optim_helper import evaluate\n",
    "from src.utils import calc_early_stopping_patience, set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d372b-2447-4ac1-a2bf-64de60ed16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic\n",
    "set_seeds(42, use_deterministic=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef937c7-5417-4e1c-adcf-997d80d133de",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb641a52-2756-4bc7-821a-2e80c8dea3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())\n",
    "DL_DATA_DIR = pathlib.Path(f\"{ROOT_DIR}/data/DL_data\")\n",
    "\n",
    "# FIG_DIR = f\"{ROOT_DIR}/doc/report_20220912/fig\"\n",
    "# os.makedirs(FIG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cffc45c-6978-4688-b2ff-18192ffaf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    logger.info(\"GPU is used.\")\n",
    "else:\n",
    "    logger.error(\"No GPU. CPU is used.\")\n",
    "    # raise Exception(\"No GPU. CPU is used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90201a3-398d-49f3-bacf-b6dd4dabbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATHS = sorted(\n",
    "    glob.glob(f\"{ROOT_DIR}/pytorch/config/new_lr_unet_gconv_change_datashape_ddp/*.yml\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87859e3b-b5fe-4915-abb6-37b6df7985ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_IS_IN_BUILD = np.load(f\"{ROOT_DIR}/data/DL_data/10/hr_is_in_build.npy\")\n",
    "LR_IS_IN_BUILD = np.load(f\"{ROOT_DIR}/data/DL_data/10/lr_is_in_build.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51976f6-d98b-4612-9a22-1c529d08878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    if \"tutorial\" in config_path:\n",
    "        continue\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "\n",
    "    _dir = f\"{ROOT_DIR}/data/DL_results/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"model_name\": config[\"model\"][\"model_name\"],\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/weights.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/learning_history.csv\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a031d-3859-43b4-bea1-05f047a2053d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6b882b-5cdc-4546-a217-0e035f7dd2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name, config_info in CONFIGS.items():\n",
    "    if not os.path.exists(config_info[\"learning_history_path\"]):\n",
    "        print(f\"{config_name} is skipped because of no result.\")\n",
    "        continue\n",
    "    df = pd.read_csv(config_info[\"learning_history_path\"])\n",
    "    cnt = calc_early_stopping_patience(df, th_max_cnt=50)\n",
    "    # print(f\"{config_name}: max cnt = {cnt}\")\n",
    "\n",
    "    assert len(df) == config_info[\"config\"][\"train\"][\"num_epochs\"]\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 15\n",
    "    fig = plt.figure(figsize=[7, 5])\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    df.plot(\n",
    "        ax=ax,\n",
    "        xlabel=\"Epochs\",\n",
    "        ylabel=config_info[\"config\"][\"train\"][\"loss\"][\"name\"],\n",
    "    )\n",
    "    ax.set_title(config_name)\n",
    "    plt.yscale(\"log\")\n",
    "\n",
    "    # fig.savefig(f\"{FIG_DIR}/{config_name}_learning_curve.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8282b3-1897-4638-b5c2-8dc99063e578",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calc test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11825e-392f-4dfa-b81e-abb44123e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./test_scores.csv\"):\n",
    "    df_results = pd.read_csv(\"./test_scores.csv\").set_index(\"Unnamed: 0\")\n",
    "    print(\"DF is read from csv\")\n",
    "else:\n",
    "    df_results = pd.DataFrame()\n",
    "    print(\"DF is created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b02259-2693-41ef-8c2a-2f48ce3eedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_name, config_info in tqdm(CONFIGS.items(), total=len(CONFIGS)):\n",
    "    if not os.path.exists(config_info[\"weight_path\"]):\n",
    "        print(f\"{config_name} is skipped because of no result.\")\n",
    "        continue\n",
    "\n",
    "    if config_name in df_results.index:\n",
    "        logger.info(f\"{config_name} already exists. so skip calculaton.\")\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"\\n{config_name} is being evaluated\")\n",
    "    config = config_info[\"config\"]\n",
    "\n",
    "    loss_fns = {\n",
    "        \"L1\": MyL1Loss(),\n",
    "        \"MaskedL1\": MaskedL1Loss(),\n",
    "        \"MaskedL1NearWall\": MaskedL1LossNearWall(),\n",
    "        \"L2\": MyL2Loss(),\n",
    "        \"MaskedL2\": MaskedL2Loss(),\n",
    "        \"MaskedL2NearWall\": MaskedL2LossNearWall(),\n",
    "        \"ResidualContinuityEq\": ResidualContinuity(config[\"data\"][\"stds\"][1:]),\n",
    "        \"AbsDiffTemperature\": AbsDiffTemperature(config[\"data\"][\"stds\"][0]),\n",
    "        \"DiffVelocityNorm\": DiffVelocityVectorNorm(config[\"data\"][\"stds\"][1:]),\n",
    "        \"AbsDiffTemperatureLevZero\": AbsDiffTemperature(\n",
    "            config[\"data\"][\"stds\"][0], lev=0\n",
    "        ),\n",
    "        \"DiffVelocityNormLevZero\": DiffVelocityVectorNorm(\n",
    "            config[\"data\"][\"stds\"][1:], lev=0\n",
    "        ),\n",
    "        \"AbsDiffDivergence\": AbsDiffDivergence(config[\"data\"][\"stds\"][1:]),\n",
    "        \"DiffOmegaVectorNorm\": DiffOmegaVectorNorm(config[\"data\"][\"stds\"][1:]),\n",
    "        \"SSIM3D_1e-7\": Ssim3dLoss(eps=1e-7),\n",
    "        \"ChannelwiseMseT\": ChannelwiseMse(i_channel=0),\n",
    "        \"ChannelwiseMseU\": ChannelwiseMse(i_channel=1),\n",
    "        \"ChannelwiseMseV\": ChannelwiseMse(i_channel=2),\n",
    "        \"ChannelwiseMseW\": ChannelwiseMse(i_channel=3),\n",
    "        \"MixedDivergenceGradientL2LossDivMse\": MixedDivergenceGradientL2LossDivMse(\n",
    "            config[\"data\"][\"stds\"][1:]\n",
    "        ),\n",
    "        \"MixedDivergenceGradientL2LossGrdMse\": MixedDivergenceGradientL2LossGrdMse(\n",
    "            config[\"data\"][\"stds\"][1:]\n",
    "        ),\n",
    "        \"MixedDivergenceGradientL2LossMse\": MixedDivergenceGradientL2LossMse(\n",
    "            config[\"data\"][\"stds\"][1:]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    test_loader = make_evaluation_dataloader_without_random_cropping(\n",
    "        config, DL_DATA_DIR, batch_size=1\n",
    "    )\n",
    "\n",
    "    model = make_model(config).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(config_info[\"weight_path\"], map_location=DEVICE))\n",
    "    model.eval()\n",
    "\n",
    "    results = evaluate(\n",
    "        dataloader=test_loader,\n",
    "        model=model,\n",
    "        loss_fns=loss_fns,\n",
    "        device=DEVICE,\n",
    "        hide_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    df_results.loc[config_name, \"ExperimentName\"] = config_info[\"experiment_name\"]\n",
    "    df_results.loc[config_name, \"ModelName\"] = config[\"model\"][\"model_name\"]\n",
    "    df_results.loc[config_name, \"LossName\"] = config[\"train\"][\"loss\"][\"name\"]\n",
    "    df_results.loc[config_name, \"LearningRate\"] = config[\"train\"][\"lr\"]\n",
    "    df_results.loc[config_name, \"NumFeat0\"] = config[\"model\"][\"num_feat0\"]\n",
    "    df_results.loc[config_name, \"NumFeat1\"] = config[\"model\"][\"num_feat1\"]\n",
    "    df_results.loc[config_name, \"NumFeat2\"] = config[\"model\"][\"num_feat2\"]\n",
    "    df_results.loc[config_name, \"NumFeat3\"] = config[\"model\"][\"num_feat3\"]\n",
    "    df_results.loc[config_name, \"NumLatentLayers\"] = config[\"model\"][\n",
    "        \"num_latent_layers\"\n",
    "    ]\n",
    "    df_results.loc[config_name, \"CroppedSizeZ\"] = config[\"data\"][\"hr_crop_size\"][0]\n",
    "    df_results.loc[config_name, \"CroppedSizeY\"] = config[\"data\"][\"hr_crop_size\"][1]\n",
    "    df_results.loc[config_name, \"CroppedSizeX\"] = config[\"data\"][\"hr_crop_size\"][2]\n",
    "\n",
    "    df_results.loc[config_name, \"TrainDatasize\"] = config[\"data\"][\"datasizes\"][\"train\"]\n",
    "    df_results.loc[config_name, \"ValidDatasize\"] = config[\"data\"][\"datasizes\"][\"valid\"]\n",
    "    df_results.loc[config_name, \"TestDatasize\"] = config[\"data\"][\"datasizes\"][\"test\"]\n",
    "    df_results.loc[config_name, \"TotalTrainDatasize\"] = (\n",
    "        config[\"data\"][\"datasizes\"][\"train\"] + config[\"data\"][\"datasizes\"][\"valid\"]\n",
    "    )\n",
    "    df_results.loc[config_name, \"WeightGradLoss\"] = config[\"train\"][\"loss\"].get(\n",
    "        \"weight_gradient_loss\", 0.0\n",
    "    )\n",
    "    df_results.loc[config_name, \"WeightDivLoss\"] = config[\"train\"][\"loss\"].get(\n",
    "        \"weight_divergence_loss\", 0.0\n",
    "    )\n",
    "    df_results.loc[config_name, \"max_discarded_lr_z_index\"] = config[\"data\"][\n",
    "        \"max_discarded_lr_z_index\"\n",
    "    ]\n",
    "\n",
    "    for k, v in results.items():\n",
    "        df_results.loc[config_name, k] = v.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8352c19-5838-48f6-8482-588895218ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea82a08-daa6-4e78-a9e8-68e823fd4c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"./test_scores.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d59092-e6c2-49c5-ab66-e6b3db3e527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del test_loader\n",
    "gc.collect()\n",
    "_ = torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b8e40-b8a8-4247-a59b-aa1762e78d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyze test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4114a-6497-41d6-8116-b76ebc92f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv(\"./test_scores.csv\").set_index(\"Unnamed: 0\")\n",
    "df_results.sort_values(\"TotalTrainDatasize\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9720f6-f238-43fb-a8e6-6420f84d4eb6",
   "metadata": {},
   "source": [
    "- Near walls or the ground, gated convs contribute to reducing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da615144-9927-4a80-8f1d-28dc0bdccd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycols = [\n",
    "    \"MixedDivergenceGradientL2LossMse\",\n",
    "    \"MixedDivergenceGradientL2LossGrdMse\",\n",
    "    \"MixedDivergenceGradientL2LossDivMse\",\n",
    "    \"SSIM3D_1e-7\",\n",
    "    \"AbsDiffTemperature\",\n",
    "    \"DiffVelocityNorm\",\n",
    "    \"AbsDiffTemperatureLevZero\",\n",
    "    \"DiffVelocityNormLevZero\",\n",
    "    \"MaskedL2NearWall\",\n",
    "]\n",
    "df_results.loc[[\"z0_2475_825_no_gconv\", \"z0_2475_825\"], ycols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e717b3-ad3d-40af-9e01-8a5aa19f994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_results.copy(deep=True).sort_values([\"max_discarded_lr_z_index\"])\n",
    "df = df[df.index != \"z0_2475_825_no_gconv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfff395-c30b-474d-aa67-2dcba56804a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ycols = [\n",
    "    # \"L1\",\n",
    "    \"MixedDivergenceGradientL2LossMse\",\n",
    "    \"MixedDivergenceGradientL2LossGrdMse\",\n",
    "    \"MixedDivergenceGradientL2LossDivMse\",\n",
    "    \"SSIM3D_1e-7\",\n",
    "    # \"ResidualContinuityEq\",\n",
    "    \"AbsDiffTemperature\",\n",
    "    \"DiffVelocityNorm\",\n",
    "    # \"AbsDiffDivergence\",\n",
    "    # \"DiffOmegaVectorNorm\",\n",
    "    # \"ChannelwiseMseT\",\n",
    "    # \"ChannelwiseMseU\",\n",
    "    # \"ChannelwiseMseV\",\n",
    "    # \"ChannelwiseMseW\",\n",
    "    \"AbsDiffTemperatureLevZero\",\n",
    "    \"DiffVelocityNormLevZero\",\n",
    "    \"MaskedL2NearWall\",\n",
    "]\n",
    "\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "fig, axes = plt.subplots(3, 3, figsize=[15, 10], sharex=True)\n",
    "\n",
    "for ax, ycol in zip(np.ravel(axes), ycols):\n",
    "    for datasize, grp in df.groupby(\"TotalTrainDatasize\"):\n",
    "        xs = grp[\"max_discarded_lr_z_index\"].values\n",
    "        ys = grp[ycol].values\n",
    "        ax.plot(xs, ys, \"o-\", label=f\"{int(datasize):04}\")\n",
    "\n",
    "    label = ycol if \"L2\" not in ycol else \"\\nL2\".join(ycol.split(\"L2\"))\n",
    "    ax.set_title(label)\n",
    "    ax.set_ylabel(label)\n",
    "    ax.set_xlabel(\"Discarded grids in z\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8aab3c-c38e-4319-b5bf-aecb201fc021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
